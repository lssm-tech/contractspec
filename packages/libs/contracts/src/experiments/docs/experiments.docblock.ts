import type { DocBlock } from '@contractspec/lib.contracts/docs';
import { registerDocBlocks } from '../../docs/registry';

export const tech_contracts_experiments_DocBlocks: DocBlock[] = [
  {
    id: 'docs.tech.contracts.experiments',
    title: 'ExperimentSpec & ExperimentEvaluator',
    summary:
      'Use experiments to test alternative workflows, data views, or themes with controlled allocations and measurable outcomes.',
    kind: 'reference',
    visibility: 'public',
    route: '/docs/tech/contracts/experiments',
    tags: ['tech', 'contracts', 'experiments'],
    body: "# ExperimentSpec & ExperimentEvaluator\n\nUse experiments to test alternative workflows, data views, or themes with controlled allocations and measurable outcomes.\n\n- Types & registry: `packages/libs/contracts/src/experiments/spec.ts`\n- Runtime evaluator: `packages/libs/contracts/src/experiments/evaluator.ts`\n- CLI wizard/template: `contractspec create experiment`\n\n## Structure\n\n```ts\nexport interface ExperimentSpec {\n  meta: ExperimentMeta;\n  controlVariant: string;\n  variants: ExperimentVariant[];\n  allocation: AllocationStrategy;\n  successMetrics?: SuccessMetric[];\n}\n```\n\n- `variants`: define UI/behavior overrides (data views, workflows, themes, policies)\n- `allocation`:\n  - `random`: 50/50 or weighted via `weight`\n  - `sticky`: deterministic hash on user/organization/session\n  - `targeted`: rule-based (policy + expression + optional percentage)\n- `successMetrics`: telemetry events + aggregation (count/avg/p95) to track outcomes\n\n### Example\n\n```ts\nexport const OnboardingSplitFormExperiment: ExperimentSpec = {\n  meta: {\n    name: 'sigil.onboarding.split_form',\n    version: '1.0.0',\n    title: 'Split onboarding form',\n    description: 'Compare single vs multi-step onboarding',\n    domain: 'onboarding',\n    owners: ['@team.onboarding'],\n    tags: ['experiment'],\n    stability: StabilityEnum.Experimental,\n  },\n  controlVariant: 'control',\n  variants: [\n    { id: 'control', name: 'Single-step form' },\n    {\n      id: 'multi_step',\n      name: 'Multi-step form',\n      overrides: [\n        { type: 'workflow', target: 'sigil.onboarding.workflow.multi_step' },\n      ],\n    },\n  ],\n  allocation: {\n    type: 'targeted',\n    rules: [\n      {\n        variantId: 'multi_step',\n        expression: \"context.attributes?.segment === 'vip'\",\n      },\n    ],\n    fallback: 'random',\n  },\n  successMetrics: [\n    {\n      name: 'Completion rate',\n      telemetryEvent: { name: 'sigil.telemetry.onboarding_completed', version: '1.0.0' },\n      aggregation: 'count',\n    },\n  ],\n};\n```\n\n## Variant evaluation\n\n```ts\nconst evaluator = new ExperimentEvaluator({\n  registry: experimentRegistry,\n  policyChecker: (policyRef, context) =>\n    policyEngine.decide({\n      action: 'experiment_targeting',\n      subject: { roles: context.flags },\n      resource: { type: 'experiment', attributes: { name: context.experiment } },\n      policies: [policyRef],\n    }).effect === 'allow',\n});\n\nconst assignment = await evaluator.chooseVariant({\n  experiment: 'sigil.onboarding.split_form',\n  userId: ctx.userId,\n  organizationId: ctx.organizationId,\n  attributes: ctx.attributes,\n});\n\nif (assignment) {\n  // Apply overrides for the chosen variant\n  applyExperimentOverrides(assignment.variant);\n}\n```\n\n- `random` uses deterministic hashing (`salt` optional) for stable splits\n- `sticky` hashes a specified attribute (userId/orgId/sessionId)\n- `targeted` evaluates rules in order; each rule can reference a PolicySpec and simple JS expressions (`context` input)\n\n## Integrations\n\n- **Feature modules**: `FeatureModuleSpec.experiments` references experiments owned by a module\n- **DataViewSpec / WorkflowSpec**: `experiments?: ExperimentRef[]` indicate which experiments modify the spec\n- **Telemetry**: success metrics reference `TelemetrySpec` events to ensure compliant tracking\n- **Policy**: targeting rules call into `PolicyEngine` via the evaluator callback to respect privacy/security\n\n## CLI workflow\n\n```\ncontractspec create experiment\n```\n\n- Prompts for control/variants, allocation strategy, targeting rules, success metrics\n- Outputs a typed `ExperimentSpec` file alongside your contracts\n\n## Best practices\n\n1. Keep experiments short-lived; increment `meta.version` when changing allocation or variants.\n2. Always declare a control variant and ensure overrides are reversible.\n3. Tie success metrics to privacy-reviewed telemetry events.\n4. Use targeting rules sparingly; combine with PolicySpec to avoid exposing experiments to unauthorized users.\n5. When an experiment wins, promote the variant to the canonical spec and retire the experiment.\n\n",
  },
];
registerDocBlocks(tech_contracts_experiments_DocBlocks);
